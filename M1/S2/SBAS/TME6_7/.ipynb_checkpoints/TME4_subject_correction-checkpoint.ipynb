{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Statistique en Bioinformatique : </b> TME5 </h1>\n",
    "<br>\n",
    "L’objectif de ce TME est: \n",
    "<br>\n",
    "<ul>\n",
    "<li> implémenter l'algorithme de Viterbi et l'estimation des paramèetres (en utilisant le Viterbi training)\n",
    "pour l'exemple du occasionally dishonest casino.   </li> \n",
    "</ul>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">\n",
    "<p>**Soumission**</p>\n",
    "<ul>\n",
    "<li>Renomer le fichier TME5_subject_st.ipynb pour NomEtudiant1_NomEtudiant3.ipynb </li>\n",
    "<li>Envoyer par email à juliana.silva_bernardes@upmc.fr, l’objet du email sera [SBAS-2018] TME5 (deadline 19/03/2018 23:59)</li>\n",
    "</ul>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introduction</h3>\n",
    "Un casino parfois malhonnête (occasionally dishonest casino) utilise 2 types de dés : fair et unfair. <br>\n",
    "La matrice de transition entre les états cachés est:<br>\n",
    "${\\cal S}=\\{F,U\\}$ (fair, unfair):\n",
    "$$\n",
    "p = \\left(\n",
    "\\begin{array}{cc}\n",
    "0.99 & 0.01\\\\\n",
    "0.05 & 0.95\n",
    "\\end{array}\n",
    "\\right)\\ ,\n",
    "$$\n",
    "\n",
    "les probabilités d'éemission des symboles \n",
    "${\\cal O} = \\{H,T\\}$ (head, tail):\n",
    "\\begin{eqnarray}\n",
    "e_F(H) =  0.5 &\\ \\ \\ \\ &\n",
    "e_F(T) = 0.5 \\nonumber\\\\\n",
    "e_U(H) = 0.9 &\\ \\ \\ \\ &\n",
    "e_U(T) = 0.1 \\nonumber\n",
    "\\end{eqnarray}\n",
    "\n",
    "<br> Et la condition initiale $\\pi^{(0)} = (1,0)$ (le jeux commence toujours avec le dés juste (fair)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercice 1</b>:\n",
    "<u>Simulation</u>: Ecrire une fonction qui simule $T$ jets de dés. \n",
    "La fonction renverra un tableau à deux colonnes correspondant \n",
    "aux valeurs simulées pour les états cachés $X_t$ \n",
    "(type de dés utilisée, “F” ou “U”) et aux symboles observées $Y_t$ \n",
    "(résultat du jet de dés, “H” ou “T”). On simulera une séquence\n",
    "de longueur 2000 qu'on gardera pour les applications ultérieures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "S = { 0:'F',1 :'U'}\n",
    "Pij = np.array([[0.99,0.01], [0.05,0.95]])\n",
    "\n",
    "O = {0:'H', 1: 'T'}\n",
    "Eij = np.array([[0.5,0.5], [0.9,0.1]])\n",
    "\n",
    "# Condition initiale\n",
    "pi0=np.array([0.5,0.5])\n",
    "\n",
    "T = 2000\n",
    "#to test\n",
    "#T = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui simule T jets de dés\n",
    "def jets(T, pi0, Eij, Pij):\n",
    "\t# Creation du tableau\n",
    "\tresultat = np.zeros((T,len(pi0)),dtype=int)\n",
    "\t#Etat initial\n",
    "\tresultat[0,0] = 0\n",
    "\tjet = np.random.rand()\n",
    "\tif jet < pi0[0]:\n",
    "\t\tresultat[0,1] = 0; resultat[0,0] = 0\n",
    "\telse : \n",
    "\t\tresultat[0,1] = 1\t\n",
    "\t# Boucle sur le reste des jets\n",
    "\tfor i in range(1,T):\n",
    "\t\tpreviousstate = resultat[i-1,0]\n",
    "\t\t# transition\n",
    "\t\tjet = np.random.rand()\n",
    "\t\tif jet <  Pij[int(previousstate),0]:\n",
    "\t\t\tresultat[i,0] = 0 \n",
    "\t\telse :\n",
    "\t\t\tresultat[i,0] = 1\n",
    "\t\t\n",
    "\t\t# Observation\n",
    "\t\tjet = np.random.rand()\n",
    "\t\tif jet <  Eij[int(resultat[i,0]),0]:\n",
    "\t\t\tresultat[i,1] = 0 \n",
    "\t\telse :\n",
    "\t\t\tresultat[i,1] = 1\n",
    "\treturn resultat\n",
    "\n",
    "def imprimerResultats(resultat):\n",
    "\tfor i in resultat : \n",
    "\t\tprint (S[i[0]], O[i[1]])\n",
    "\n",
    "jettest = jets(T)\n",
    "#imprimerResultats(jettest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercice 2</b>: <u>Algorithme de Viterbi </u>: Ecrire une fonction qui permet\n",
    "de déterminer la séquence $(i^\\star_t)_{t=0:T}$ d'états cachés\n",
    "plus probable, donnés les paramètres du modèle et la séquence\n",
    "des symboles émis. Appliquer cette fonction aux résultats de la \n",
    "simulation (2éme colonne) et comparer $(i^\\star_t)_{t=0:T}$ avec\n",
    "les vrais états cachés (1ère colonne de la simulation). Est-ce \n",
    "que vous pouvez comprendre les différences entre $(i^\\star_t)_{t=0:T}$\n",
    "et $(i_t)_{t=0:T}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ..., \n",
      " [0]\n",
      " [0]\n",
      " [0]] -1346.0820408\n"
     ]
    }
   ],
   "source": [
    "def viterbi(obsjets, T, pi0, Eij, Pij):\n",
    "\tdelta = np.zeros((T,len(pi0)))\n",
    "\tpath = np.zeros((T,len(pi0)), dtype=int)\n",
    "\t# Initialisation\n",
    "\tfor i in range(len(pi0)):\n",
    "\t\tdelta[0,i] = np.log(pi0[i])  + np.log(Eij[i,int(obsjets[0])])\n",
    "\t\tpath[0,i] = -1\n",
    "\t# Recursion\n",
    "\tfor t in range(1,T):\n",
    "\t\tfor i in range(len(pi0)):\n",
    "\t\t\tlisteSum = []\n",
    "\t\t\tfor j in range(len(pi0)):\n",
    "\t\t\t\tsum1 = (delta[t-1,j] + np.log(Pij[j,i]))\n",
    "\t\t\t\tlisteSum.append(sum1)\n",
    "\t\t\tdelta[t,i] = np.log(Eij[i, int(obsjets[t])]) + max(listeSum)\n",
    "\t\t\tarMax = np.argmax(listeSum)\n",
    "\t\t\tpath[t,i] = arMax\n",
    "\t# Backtracking\n",
    "\tpathEtats = np.zeros((len(obsjets),1),dtype=int)\n",
    "\tmaximEtat = np.argmax(delta[T-1])\n",
    "\tprobabilite = max(delta[T-1]) \n",
    "\tpathEtats[T-1] = maximEtat\n",
    "\tfor t in range (1,len(path)):\n",
    "\t\tmaximEtat = path[T-t, maximEtat] \n",
    "\t\tpathEtats[T-1-t] = maximEtat\n",
    "\treturn pathEtats, probabilite\n",
    "\n",
    "paths, probabilite = viterbi(jettest[:,1], T, pi0, Eij, Pij)\n",
    "print (paths, probabilite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercice 3</b>: <u>Estimation des paramètres</u>\n",
    "<br>\n",
    "3.1) Ecrire une fonction qui utilise tous les résultats de la simulation\n",
    "(états et symboles) pour compter les nombres d'occurrence $N_{ij}$ est $M_{iO}$ définis\n",
    "en cours. Estimer $p_{ij}$ est $e_i(O)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimerPathViterbi(resultat):\n",
    "\tfor i in range(len(resultat)):  \n",
    "\t\tprint (S[paths[i][0]])\n",
    "\n",
    "\n",
    "def designer(jets, paths):\n",
    "\tplt.plot(jets, 'blue')\n",
    "\tplt.plot(paths, 'red')\n",
    "\tplt.axis([0, T, 0, 1.5])\n",
    "\tplt.xlabel(\"B = Viterbi, R = Vrai\")\n",
    "\tplt.show()\n",
    "\n",
    "def imprimerResultatsViterbi(resultat, paths):\n",
    "\tcomptage = 0.\n",
    "\tfor i in range(len(resultat)): \n",
    "\t\t#print ('Vrai : ', S[resultat[i]], ' Obtenu Viterbi: ', S[paths[i][0]])\n",
    "\t\tif S[resultat[i]] == S[paths[i][0]]:\n",
    "\t\t\tcomptage = comptage + 1\n",
    "\tpourcentage = (comptage / len(resultat))*100\n",
    "\tprint ('Pourcentage de vraissemblance %: ', pourcentage, ' Qte. egale: ', comptage, ' Taille : ', T)\n",
    "\tdesigner(jettest[:,0], paths)\n",
    "\n",
    "#imprimerResultatsViterbi(jettest[:,0], paths)\n",
    "\n",
    "def normalisation(matrix):\n",
    "\tfor line in range(len(matrix)):\n",
    "\t\tsommeLine = np.sum(matrix[line])\n",
    "\t\tif sommeLine != 0:\n",
    "\t\t\tfor element in range(len(matrix[line])):\n",
    "\t\t\t\tmatrix[line,element] = matrix[line,element]/sommeLine\n",
    "\treturn matrix\n",
    "\n",
    "def estimationParametres(jets, s, o):\n",
    "\tPij = np.zeros((s,s))\n",
    "\tEia = np.zeros((s,o))\n",
    "\tpi0 = np.zeros(s)\n",
    "\t\n",
    "\tfor i in range(len(jets)-1):\n",
    "\t\tif i == 0:\n",
    "\t\t\tpi0[jets[i][0]] = 1\n",
    "\t\tetat1 = jets[i][0]  \n",
    "\t\tetat2 = jets[i+1][0]\n",
    "\t\tPij[etat1][etat2] = Pij[etat1][etat2] + 1\n",
    "\t\ta = jets[i][1]\n",
    "\t\tEia[etat1][a] = Eia[etat1][a] +1\n",
    "\treturn  normalisation(Pij), normalisation(Eia), pi0\n",
    "\n",
    "def imprimerParametres(jettest, s, o):\n",
    "\tPij, Eia, pi0 = estimationParametres(jettest, 2, 2)\n",
    "\tprint (\"===Ini Estimation paramètres===\")\n",
    "\tprint (\"Pij\")\n",
    "\tprint (Pij)\n",
    "\tprint (\"Eia\")\n",
    "\tprint (Eia)\n",
    "\tprint (\"pi0\")\n",
    "\tprint (pi0)\n",
    "\tprint (\"===Fin Estimation paramètres===\")\n",
    "    \n",
    "#3.1\n",
    "imprimerParametres(jettest, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2) <u> Viterbi training </u>: Ecrire une fonction qui utilise \n",
    "seulement la séquence $(O_t)_{t=0:T}$ pour estimer les \n",
    "paramètres $p_{ij}$ est $e_i(O)$. Vous devez donner comme paramètre le\n",
    "nombre d'Interation. Comparer les résultats de 3.1 et de 3.2 (3.2 avec plusieurs restarts,\n",
    "et avec initialisation des paramètres alèatoire).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialisation(s, o):\n",
    "\tPij = np.zeros((s,s))\n",
    "\tEia = np.zeros((s,o))\n",
    "\tpi0 = np.zeros(s)\n",
    "\tp = np.random.rand()\n",
    "\tpi0[0] = p\n",
    "\tpi0[1] = 1-p\n",
    "\t\n",
    "\tfor i in range (len(Pij)):\n",
    "\t\tp = np.random.rand()\n",
    "\t\tPij[i,0] = p\n",
    "\t\tPij[i,1] = 1-p\n",
    "\t\tp = np.random.rand()\n",
    "\t\tEia[i,0] = p\n",
    "\t\tEia[i,1] = 1-p\n",
    "\treturn Pij, Eia, pi0\n",
    "  \n",
    "def creationArrayIetA(etats, obs, T, s):\n",
    "\tresultat = np.zeros((T,s),dtype=int)\n",
    "\tfor i in range(T):\n",
    "\t\tresultat[i,0] = etats[i]\n",
    "\t\tresultat[i,1] = obs[i]\n",
    "\treturn resultat\n",
    "\t\n",
    "\n",
    "def calculeVraissamblance(i,a,pi0, T, p, e):\n",
    "\tlV = np.log(e[i[0],int(a[0])])\n",
    "\tfor t in range (1,T):\n",
    "\t\tlV += np.log(p[i[t-1], i[t]]) + np.log(e[i[t],int(a[t])])\n",
    "\treturn lV\n",
    "\n",
    "def viterbiTraining(obs, T, s, o):\n",
    "\t# Initialisation\n",
    "\tPij, Eia, pi0 = initialisation(s,o)\n",
    "\tcritere = 1e-4\n",
    "\tlogV = -10000\n",
    "\tflag = 1\n",
    "\n",
    "\twhile(flag==1):\n",
    "\t\tpath, probabilite = viterbi(obs, T, pi0, Eia, Pij)\n",
    "\t\tjeuEtatsObs = creationArrayIetA(path,obs, T, s )\n",
    "\t\tPij, Eia, pi0 = estimationParametres(jeuEtatsObs, s, o)\n",
    "\t\t'''\n",
    "\t\tprint \"\"\n",
    "\t\tprint \"Pij\"\n",
    "\t\tprint Pij\n",
    "\t\tprint \"Eia\"\n",
    "\t\tprint Eia\n",
    "\t\t'''\n",
    "\t\tlogAux = calculeVraissamblance(jeuEtatsObs[:,0],jeuEtatsObs[:,1],pi0, T, Pij, Eia)\n",
    "\t\t#print \"Log Vrai: \", logAux, \"Log Vrai Posterieur : \", logV\n",
    "\t\tif abs(logAux-logV) < critere:\n",
    "\t\t\tflag = 0\n",
    "\t\tlogV = logAux\n",
    "\treturn Pij, Eia, pi0, logV\n",
    "\n",
    "def imprimerParametresViterbiTraining(jettest, T, s, o):\n",
    "    Pij, Eia, pi0, logV = viterbiTraining(jettest, T, 2, 2)\n",
    "    print (\"===Ini Paramètres Viterbi Training===\")\n",
    "    print (\"Pij\")\n",
    "    print (Pij)\n",
    "    print (\"Eia\")\n",
    "    print (Eia)\n",
    "    print (\"pi0\")\n",
    "    print (pi0)\n",
    "    print (\"LogV\")\n",
    "    print (logV)\n",
    "    print (\"===Fin Paramètres Viterbi Training===\")\n",
    "\n",
    "\n",
    "imprimerParametresViterbiTraining(jettest[:,1], T, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualiser graphiquement les résultats.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3) <u>Viterbi training deuxime version </u> Ecrivez une version de 3.3 qui\\\\\n",
    "- part plusieurs fois (100x) d'une initialisation aléatoire des \n",
    "paramètres de l'HMM,\\\\\n",
    "- utilise Viterbi training pour estimer les paramètres,\\\\\n",
    "- calcule la log-vraisemblance pour les paramètres estimés,\\\\\n",
    "- sauvegarde seulement l'estimation avec la valeur maximale de la\n",
    "log-vraisemblance.\n",
    "Qu'est-ce que vous observez?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbiTrainingOptionnel(obs, T, s, o, iterations):\n",
    "\tresultat = [0,0,0,-10000]\n",
    "\tfor i in range (iterations):\n",
    "\t\tPij, Eia, pi0, logV = viterbiTraining(obs, T, s, o)\n",
    "\t\tif logV > resultat[3] :\n",
    "\t\t\tresultat = [Pij, Eia, pi0, logV]\n",
    "\treturn resultat\n",
    "\n",
    "\n",
    "def imprimerParametresViterbiTrainingOptionnel(jettest, T, s, o, iterations):\n",
    "\tresultat = viterbiTrainingOptionnel(jettest, T, 2, 2, iterations)\n",
    "\tprint (\"===Ini Paramètres Viterbi Training Optionnel===\")\n",
    "\tprint (\"Pij\")\n",
    "\tprint (resultat[0])\n",
    "\tprint (\"Eia\")\n",
    "\tprint (resultat[1])\n",
    "\tprint (\"pi0\")\n",
    "\tprint (resultat[2])\n",
    "\tprint (\"LogV\")\n",
    "\tprint (resultat[3])\n",
    "\tprint (\"===Fin Paramètres Viterbi Training Optionnel===\")\n",
    "\n",
    "\n",
    "imprimerParametresViterbiTrainingOptionnel(jettest[:,1], T, 2, 2, 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
